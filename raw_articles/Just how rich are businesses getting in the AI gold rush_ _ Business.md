# Just how rich are businesses getting in the AI gold rush_ _ Business

<img src="https://images.weserv.nl/?url=www.economist.com/img/b/1280/720/90/media-assets/image/20240323_WBD001.jpg" /><div></div><p><span>B</span><small>arely a day</small> goes by without excitement about <a href="https://www.economist.com/topics/artificial-intelligence">artificial intelligence (<small>AI</small>)</a> sending another company’s market value through the roof. Earlier this month the share price of Dell, a hardware manufacturer, jumped by over 30% in a day because of hopes that the technology will boost sales. Days later Together <small>AI</small>, a cloud-computing startup, raised new funding at a valuation of $1.3bn, up from $500m in November. One of its investors is <a href="https://www.economist.com/the-economist-explains/2024/02/27/why-do-nvidias-chips-dominate-the-ai-market">Nvidia</a>, a maker of <small>AI</small> chips that is itself on an extended bull run. Before the launch of Chat<small>GPT</small>, a “generative” <small>AI</small> that responds to queries in uncannily humanlike ways,<!-- --> in November 2022 its market capitalisation was about $300bn, similar to that of Home Depot, a home-improvement chain. Today it sits at $2.3trn, $300bn or so short of Apple’s.</p><p>The relentless stream of <small>AI </small>headlines makes it hard to get a sense of which businesses are real winners in the <small>AI </small>boom—and which will win in the longer run. To help answer this question <i>The Economist</i> has looked where value has accrued so far and how this tallies with the expected sales of products and services in the <small>AI</small> “stack”, as technologists call the various layers of hardware and software on which <small>AI</small> relies to work its magic. On March 18th many companies up and down the stack will descend on San Jose for a four-day jamboree hosted by Nvidia. With talks on everything from robotics to drug discovery, the shindig will show off the latest <small>AI</small> innovations. It will also highlight furious competition between firms within layers of the stack and, increasingly, between them. </p><div><div><div id="econ-1"></div></div></div><div><figure><span><img alt="" src="https://www.economist.com/img/b/608/1156/90/media-assets/image/20240323_EPC964.png" /></span></figure><p>Our analysis examined four of these layers and the companies that inhabit them: <small>AI</small>-powered applications sold to businesses outside the stack; the <small>AI</small> models themselves, such as <small>GPT</small>-4, the brain behind Chat<small>GPT</small>, and repositories of them (for example, Hugging Face); the cloud-computing platforms which host many of these models and some of the applications (Amazon Web Services, Google Cloud Platform, Microsoft Azure); and the hardware, such as semiconductors (made by firms such as <small>AMD</small>, Intel and Nvidia), servers (Dell) and networking gear (Arista), responsible for the clouds’ computing oomph (see chart 1). </p><p>Technological breakthroughs tend to elevate new tech giants. The <small>PC </small>boom in the 1980s and 1990s propelled Microsoft, which made the Windows operating system, and Intel, which manufactured the chips needed to run it, to the top of the corporate pecking order. By the 2000s “Wintel” was capturing four-fifths of the operating profits from the <small>PC </small>industry, according to Jefferies, an investment bank. The smartphone era did the same to Apple. Only a few years after it launched the iPhone in 2007, it was capturing more than half of handset-makers’ global operating profits.</p></div><div><figure><span><img alt="" src="https://www.economist.com/img/b/608/701/90/media-assets/image/20240323_EPC824.png" /></span></figure><p>The world is still in the early days of the generative-<small>AI</small> epoch. Even so, it has already been immensely lucrative. All told, the 100 or so companies that we examined have together created $8trn in value for their owners since its start—which, for the purposes of this article, we define as October 2022, just before the launch of Chat<small>GPT</small> (see chart 2). Not all of these gains are the result of the <small>AI </small>frenzy—stockmarkets have been on a broader tear of late—but many are.</p><p>At every layer of the stack, value is becoming more concentrated in a handful of leading firms. In hardware, model-making and applications, the biggest three companies have increased their share of overall value created by a median of 14 percentage points in the past year and a half. In the cloud layer Microsoft, which has a partnership with Chat<small>GPT</small>’s maker, Open<small>AI</small>, has pulled ahead of Amazon and Alphabet (Google’s parent company). Its market capitalisation now accounts for 46% of the cloud trio’s total, up from 41% before the release of Chat<small>GPT</small>.</p></div><h2>Skimming the cream</h2><p>The spread of value is uneven between layers, too. In absolute terms the most riches have accrued to the hardware-makers. This bucket includes chip firms (such as Nvidia), companies that build servers (Dell) and those that make networking equipment (Arista). In October 2022 the 27 public hardware companies in our sample were worth around $1.5trn. Today that figure is $5trn. This is what you would expect in a technology boom: the underlying physical infrastructure needs to be built first in order for software to be offered. In the late 1990s, as the internet boom was getting going, providers of things like modems and other telecoms gubbins, such as Cisco and WorldCom, were the early winners.</p><div><div><div id="econ-2"></div></div></div><p>So far the host of the San Jose gabfest is by far the biggest victor. Nvidia accounts for some 57% of the increase in the market capitalisation of our hardware firms. The company makes more than 80% of all <small>AI </small>chips, according to <small>IDC</small>, a research firm. It also enjoys a near-monopoly in the networking equipment used to yoke the chips together inside the <small>AI</small> servers in data centres. Revenues from Nvidia’s data-centre business more than tripled in the 12 months to the end of January, compared with the year before. Its gross margins grew from 59% to 74%. </p><p>Nvidia’s chipmaking rivals want a piece of these riches. Established ones, such as <small>AMD </small>and Intel, are launching rival products. So are startups like Groq, which makes super-fast <small>AI </small>chips, and Cerebras, which makes super-sized ones. Nvidia’s biggest customers, the three cloud giants, are all designing their own chips, too—as a way both to reduce reliance on one provider and to steal some of Nvidia’s juicy margins for themselves. Lisa Su, chief executive of <small>AMD</small>, has forecast that revenues from the sale of <small>AI </small>chips could balloon to $400bn by 2027, from $45bn in 2023. That would be far too much for Nvidia alone to digest.</p><p>As <small>AI</small> applications become more widespread, a growing share of that demand will also shift from chips required for training models, which consists in analysing mountains of data in order to teach algorithms to predict the next word or pixel in a sequence, to those needed actually to use them to respond to queries, (“inference”, in tech-speak). In the past year about two-fifths of Nvidia’s <small>AI </small>revenues came from customers using its chips for inference. Experts expect some inference to start moving from specialist graphics-processing units (<small>GPU</small>s), which are Nvidia’s forte, to general-purpose central processing units (<small>CPU</small>s) like those used in laptops and smartphones, which are dominated by <small>AMD </small>and Intel. Before long even some training may be done on <small>CPU</small>s rather than <small>GPU</small>s. </p><p>Still, Nvidia’s grip on the hardware market seems secure for the next few years. Startups with no track record will struggle to convince big clients to reconfigure corporate hardware systems for their novel technology. The cloud giants’ deployment of their own chips is still limited. And Nvidia has <small>CUDA</small>, a software platform which allows customers to tailor chips to their needs. It is popular with programmers and makes it hard for customers to switch to rival semiconductors, which <small>CUDA</small> does not support. </p><p>Whereas hardware wins the value-accrual race hands down in absolute terms, it is the independent model-makers that have enjoyed the biggest proportional gains. The collective value of 11 such firms we have looked at has jumped from $29bn to about $138bn in the past 16 months. Open<small>AI </small>is thought to be worth some $100bn, up from $20bn in October 2022. Anthropic’s valuation surged from $3.4bn in April 2022 to $18bn. Mistral, a French startup founded less than a year ago, is now worth around $2bn. </p><p>Some of that value is tied up in hardware. The startups buy piles of chips, mostly from Nvidia, in order to train their models. Imbue, which like Open<small>AI</small> and Anthropic is based in San Francisco, has 10,000 such chips. Cohere, a Canadian rival, has 16,000. These semiconductors can sell for tens of thousands of dollars apiece. As the models get ever more sophisticated, they need ever more. <small>GPT</small>-4 reportedly cost about $100m to train. Some suspect that training its successor could cost Open<small>AI</small> ten times as much. </p><div><div><div id="econ-3"></div></div></div><p>Yet the model-makers’ true worth lies in their intellectual property, and the profits that it may generate. The true extent of those profits will depend on just how fierce competition among model providers will get—and how long it will last. Right now the rivalry is white hot, which may explain why the layer has not gained as much value in absolute terms. </p><p>Although Open<small>AI</small> seized an early lead, challengers have been catching up fast. They have been able to tap the same data as the maker of Chat<small>GPT</small> (which is to say text and images on the internet) and, also like it, free of charge. Anthropic’s Claude 3 is snapping at <small>GPT</small>-4’s heels. Four months after the release of <small>GPT</small>-4, Meta, Facebook’s parent company, released Llama 2, a powerful rival that, in contrast to Open<small>AI</small>’s and Anthropic’s proprietary models, is open and can be tinkered with at will by others. In February Mistral, which has fewer than 40 employees, wowed the industry by releasing an open model whose performance almost rivals that of <small>GPT</small>-4, despite requiring much less computational power to train and run. </p><p>Even smaller models increasingly offer good performance at a low price, points out Stephanie Zhan of Sequoia, a venture-capital firm. Some are designed for specific tasks. A startup called Nixtla developed Time<small>GPT</small>, a model for financial forecasting. Another, Hippocratic <small>AI</small>, has trained its model on data from exams to enter medical school, to give accurate medical advice.</p><p>The abundance of models has also enabled the growth of the application layer. The value of the 19 publicly traded software companies in our application group has jumped by $1.1trn, or 35%, since October 2022. This includes big software providers that are adding generative <small>AI </small>to their services. Zoom uses the technology to let users summarise video calls. ServiceNow, which provides tech, human-resources and other support to companies, has introduced chatbots to help resolve customers’ <small>IT</small> queries. Adobe, maker of Photoshop, has an app called Firefly, which uses <small>AI</small> to edit pictures. </p><p>Newcomers are adding more variety. “There’s An <small>AI</small> For That”, a website, counts over 12,000 applications, up from fewer than 1,000 in 2022. DeepScribe helps transcribe doctors’ notes. Harvey <small>AI </small>assists lawyers. More idiosyncratically, 32 chatbots promise “sarcastic conversation” and 20 generate tattoo designs. Fierce competition and low barriers to entry mean that some, if not many, applications could struggle to capture value. </p><p>Then there is the cloud layer. The combined market capitialsation of Alphabet, Amazon and Microsoft has jumped by $2.5trn since the start of the <small>AI</small> boom. Counted in dollars that is less than three-quarters of the growth of the hardware layer, and barely a quarter in percentage terms. Yet compared with actual revenues that <small>AI</small> is expected to generate for the big-tech trio in the near term, this value creation far exceeds that in all the other layers. It is 120 times the $20bn in revenue that generative <small>AI</small> is forecast to add to the cloud giants’ sales in 2024. The comparable ratio is about 40 for the hardware firms and around 30 for the model-makers.</p><div><figure><span><img alt="" src="https://www.economist.com/img/b/608/662/90/media-assets/image/20240323_EPC825.png" /></span></figure><p>This implies that investors believe that the cloud giants will be the biggest winners in the long run. The companies’ ratio of share price to earnings, another gauge of expected future profits, tells a similar story. The big three cloud firms average 29. That is above 50% higher than for the typical non-tech firm in the <small>S</small>&amp;<small>P</small> 500 index of large American companies—and up from 21 in early 2023 (see chart 3).</p></div><div><figure><span><img alt="" src="https://www.economist.com/img/b/608/967/90/media-assets/image/20240323_EPC832.png" /></span></figure><p>Investors’ cloud bullishness can be explained by three factors. First, the tech titans possess all the ingredients to develop world-beating <small>AI</small> systems: troves of data, armies of researchers, huge data centres and plenty of spare cash. Second, the buyers of <small>AI </small>services, such as big corporations, prefer to do business with established commercial parters than with untested upstarts (see chart 4). Third, and most important, big tech has the greatest potential to control every layer of the stack, from chips to applications. Besides designing some of their own chips, Amazon, Google and Microsoft are investing in both models and applications. Of the 11 model-makers in our sample, nine have the support of at least one of the three giants. That includes the Microsoft-backed Open<small>AI</small>, Anthropic (Google and Amazon) and Mistral (Microsoft again).</p></div><h2>Have the layer cake and eat it </h2><p>The potential profits that come from controlling more of the layers are also leading hitherto layer-specific firms to branch out. Open<small>AI</small>’s in-house venture-capital arm has invested in 14 companies since its launch in January 2021, including Harvey <small>AI </small>and Ambience Healthcare, another medical<!-- --> startup. Sam Altman, boss of Open<small>AI</small>, is reportedly seeking investors to bankroll a pharaonic $7trn chipmaking venture. </p><p>Nvidia is becoming more ambitious, too. It has taken stakes in seven of the model-makers, and now offers its own <small>AI</small> models. It has also invested in startups such as Together <small>AI </small>and CoreWeave, which compete with its big cloud customers. At its San Jose event it is expected to unveil a snazzy new <small>GPU</small> and, just maybe, <small>AI</small> tools from other layers of the stack. The <small>AI</small> boom’s biggest single value-creator is in no mood to cede its crown. <span>■</span></p><br /><hr /><div>获取更多RSS：<br /><a href="https://feedx.net" style="color: orange;" target="_blank">https://feedx.net</a> <br /><a href="https://feedx.run" style="color: orange;" target="_blank">https://feedx.run</a><br /></div>